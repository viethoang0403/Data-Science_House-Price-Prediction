# -*- coding: utf-8 -*-
"""build_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uHssmviv9vJbqptrZmqTYON5NCdvojGt

# 1. Chọn các đặc trưng để xây dựng mô hình

##1.1. Lấy dữ liệu đã xử lý

Import thư viện
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import date
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

"""Dữ liệu từ file clean-data:"""

train_df = pd.read_csv('./clean_data.csv')
train_df_temp = train_df.copy()
train_df_temp

"""##1.2. Lược bỏ những cột không cần thiết và thêm đặc trưng

Những cột bị loại bỏ trong dự án: City
"""

train_df_temp.drop('City', axis= 1, inplace = True)

"""Chuyển đặc trưng Date sang số thứ tự ngày từ ngày đầu tiên."""

train_df_temp['Date'] = pd.to_datetime(train_df_temp['Date'])
train_df_temp['Date'] = train_df_temp['Date'].map(pd.Timestamp.toordinal)

"""Tạo thêm đặc trưng cho bảng dữ liệu

Dựa vào đặc trưng: 'Title' để tạo thêm 6 đặc trưng: isNew(phòng mới hay cũ) , hasFurniture (có nội thất không), liveTogether(ở ghép/ktx), isWholeHouse (có phải nhà nguyên căn không), isApartment (có phải căn hộ không), isNearCenter (có gần trung tâm không)
"""

def isWholeHouse(df):
    df["Title"] = df["Title"].str.lower()
    e = ['nguyên']
    df['isWholeHouse'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
def isLiveTogether(df):
    df["Title"] = df["Title"].str.lower()
    e = ['ghép','share',"ktx",'túc']
    df['isLiveTogether'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
def isApartment(df):
    df["Title"] = df["Title"].str.lower()
    e = ['hộ','cư', 'chdv']
    df['isApartment'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
def isNew(df):
    df["Title"] = df["Title"].str.lower()
    e = ['mới', 'vừa', 'xây']
    df['isNew'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
def isNearCenter(df):
    df["Title"] = df["Title"].str.lower()
    e = ['tâm', 'tam']
    df['isNearCenter'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
def hasFurniture(df):
    df["Title"] = df["Title"].str.lower()
    e = ['nội thất', 'noi that', 'tiện nghi','tiện ích','cao cấp','cao cap','hiện đại','hien dai']
    df['hasFurniture'] = df["Title"].apply(lambda x: 'yes' if any(i in x for i in e) else 'no')
    return df
train_df_temp = isNew(train_df_temp)
train_df_temp = isNearCenter(train_df_temp)
train_df_temp = hasFurniture(train_df_temp)
train_df_temp = isWholeHouse(train_df_temp)
train_df_temp = isLiveTogether(train_df_temp)
train_df_temp = isApartment(train_df_temp)

train_df_temp

"""##1.3 Đánh giá các đặc trưng

Ta sẽ dùng hàm get_dummies để chuyển cột dạng Categorical sang Numerical theo phương pháp one hot encoding

Lý do dùng: Vì các cột dạng categorical không có dạng order (có thứ tự) nên dùng one hot encoding sẽ đem lại hiệu quả cao hơn so với phương pháp encoding khác
"""

df_new = train_df_temp.drop(columns=['Id', 'Title', 'Price(Triệu/tháng)', 'Square(m²)'])

df_new = pd.get_dummies(df_new)
# df_new['Date'] = train_df_temp['Date']
df_new['Square'] = train_df_temp['Square(m²)']
df_new['Price'] = train_df_temp['Price(Triệu/tháng)']
df_new

"""Bỏ đi những cột có tương quan thấp với giá"""

corr_price = df_new.corr()['Price']
drop_columns = corr_price[abs(corr_price)<0.01].index
df_new.drop(columns = drop_columns,inplace = True)

"""Như vậy, ta sẽ sử dụng những đặc trưng như sau để xây dựng mô hình"""

df_new.drop(columns=['Price']).columns.tolist()

df_new.to_csv('clean_data_new.csv')

"""# 2. Xây dựng mô hình

Khai báo thư viện và đầu vào
"""

from sklearn.linear_model import LinearRegression,Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
import time
X = df_new.drop(columns=['Price'])
y = df_new['Price']

"""## 2.1. Chia các tập train - test

Chia tập train/test với tỷ lệ là 75:25
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=42)

"""## 2.2. Chọn các mô hình

Ta sẽ dùng phương pháp K Fold Cross Validation để đánh giá và chọn ra các mô hình tốt nhất. Sau khi chạy thử với nhiều k thì tụi em chọn k=7 vì nó có hiệu quả tốt nhất.

Lý do dùng: Bởi vì tập dữ liệu khá nhỏ, nếu chia ra các tập train/val/test thì không thật sự đo được độ hiệu quả của mô hình (vì mỗi tập quá ít dữ liệu). Dùng K Fold Cross Validation thì mọi phần trong tập train sẽ được dùng cho cả việc train và test, nhờ đó ta sẽ đánh giá chính xác hơn độ hiệu quả của mô hình.
"""

from sklearn.model_selection import cross_val_score

"""
Ta sẽ chọn các thuật toán là LinearRegression, Ridge, Lasso, KNeighborsRegressor, RandomForestRegressor"""

model = LinearRegression()
scores = cross_val_score(model, X_train, y_train, cv=7)
scores.mean().round(5)

model = Ridge()
scores = cross_val_score(model, X_train, y_train, cv=7)
scores.mean().round(5)

model = Lasso()
scores = cross_val_score(model, X_train, y_train, cv=7)
scores.mean().round(5)

model = KNeighborsRegressor()
scores = cross_val_score(model, X_train, y_train, cv=7)
scores.mean().round(5)

model = RandomForestRegressor()
scores = cross_val_score(model, X_train, y_train, cv=7)
scores.mean().round(5)

"""Ta sẽ chọn ra 3 mô hình có điểm cao nhất là Linear Regression, Ridge, Random Forest

# 3. Tiến hành huấn luyện mô hình

Cho các mô hình này lần lượt chạy trên tập train và test để đo độ hiệu quả của chúng.

Ta sẽ tính các giá trị đo độ lỗi như sau:

MAE: lỗi trị tuyệt đối trung bình

MSE: lỗi bình phương trung bình

RMSE: sai số bình phương trung bình căn

R2_score: mức độ phù hợp của mô hình với tập dữ liệu

##3.1. Linear Regression
"""

model_LN = LinearRegression()
model_LN.fit(X_train,y_train)

print("======TRAIN======")
y_pre_train = model_LN.predict(X_train)
score_train = mean_absolute_error(y_train,y_pre_train).round(5)
mse_score = mean_squared_error(y_train,y_pre_train).round(5)
rmse = mean_squared_error(y_train,y_pre_train,squared = False).round(5)
score_r2 = round(r2_score(y_train,y_pre_train), 5)
print("Train error (MAE): {}".format(score_train))
print("Train error (MSE): {}".format(mse_score))
print("Train error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
print("======TEST======")
y_pre_test = model_LN.predict(X_test)
score_test = mean_absolute_error(y_test,y_pre_test).round(5)
mse_score = mean_squared_error(y_test,y_pre_test).round(5)
rmse = mean_squared_error(y_test,y_pre_test,squared = False).round(5)
score_r2 = round(r2_score(y_test,y_pre_test), 5)
print("Test error (MAE): {}".format(score_test))
print("Test error (MSE): {}".format(mse_score))
print("Test error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
sns.regplot(x = y_test, y = y_pre_test)
plt.title('Linear Regression')
plt.xlabel('Actual')
plt.ylabel('Predict')
plt.xticks(range(0,12,1))
plt.yticks(range(0,12,1))
plt.show()

"""Trên tập train Linear thấy độ lỗi không cao nhưng R^2score lại thấp và khi cho chạy với tập test thì lại có kết quả không tốt hơn tập train.

##3.2. Ridge
"""

model = Ridge()
model.fit(X_train,y_train)

print("======TRAIN======")
y_pre_train = model.predict(X_train)
score_train = mean_absolute_error(y_train,y_pre_train).round(5)
mse_score = mean_squared_error(y_train,y_pre_train).round(5)
rmse = mean_squared_error(y_train,y_pre_train,squared = False).round(5)
score_r2 = round(r2_score(y_train,y_pre_train), 5)
print("Train error (MAE): {}".format(score_train))
print("Train error (MSE): {}".format(mse_score))
print("Train error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
print("======TEST======")
y_pre_test = model.predict(X_test)
score_test = mean_absolute_error(y_test,y_pre_test).round(5)
mse_score = mean_squared_error(y_test,y_pre_test).round(5)
rmse = mean_squared_error(y_test,y_pre_test,squared = False).round(5)
score_r2 = round(r2_score(y_test,y_pre_test), 5)
print("Test error (MAE): {}".format(score_test))
print("Test error (MSE): {}".format(mse_score))
print("Test error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
sns.regplot(x = y_test, y = y_pre_test)
plt.title('Ridge Regression')
plt.xlabel('Actual')
plt.ylabel('Predict')
plt.xticks(range(0,12,1))
plt.yticks(range(0,12,1))
plt.show()

"""Tương tự thì ở tập train Ridge có độ lỗi không cao nhưng R^2score lại thấp và khi cho chạy với tập test thì lại có kết quả không tốt hơn tập train.

##3.3. Random Forest
"""

model = RandomForestRegressor()
model.fit(X_train,y_train)

print("======TRAIN======")
y_pre_train = model.predict(X_train)
score_train = mean_absolute_error(y_train,y_pre_train).round(5)
mse_score = mean_squared_error(y_train,y_pre_train).round(5)
rmse = mean_squared_error(y_train,y_pre_train,squared = False).round(5)
score_r2 = round(r2_score(y_train,y_pre_train), 5)
print("Train error (MAE): {}".format(score_train))
print("Train error (MSE): {}".format(mse_score))
print("Train error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
print("======TEST======")
y_pre_test = model.predict(X_test)
score_test = mean_absolute_error(y_test,y_pre_test).round(5)
mse_score = mean_squared_error(y_test,y_pre_test).round(5)
rmse = mean_squared_error(y_test,y_pre_test,squared = False).round(5)
score_r2 = round(r2_score(y_test,y_pre_test), 5)
print("Test error (MAE): {}".format(score_test))
print("Test error (MSE): {}".format(mse_score))
print("Test error (RMSE): {}".format(rmse))
print("R2 score : {}".format(score_r2))
sns.regplot(x = y_test, y = y_pre_test)
plt.title('RandomForestRegressor')
plt.xlabel('Actual')
plt.ylabel('Predict')
plt.xticks(range(0,12,1))
plt.yticks(range(0,12,1))
plt.show()

"""# 4. Đánh giá chung

Nhìn chung, cả 3 mô hình được chọn để xây dựng: Linear Regression, Ridge, Random Forest và kể cả phương pháp Ensemble(stacking) kết hợp nhiều mô hình nhưng vẫn chỉ cho R2score ở mức 0.5. Chưa đạt kì vọng ban đầu nhóm đề ra.

Nguyên nhân chủ quan có thể là do xử lý dữ liệu chưa triệt để (cũng rất khó vì nhóm đã làm rất kỹ phần xử lý tiền dữ liệu). Nguyên nhân khách quan là do giá nhà ở trang web thu thập cung cấp thông tin chưa thực sự sát với thị trường, còn mang nhiều sự cảm tính, và biến động giá nhà ở Việt Nam là rất lớn.

Phương án chính: Loại bỏ nhiễu bằng cách quan sát biểu đồ, và loại bỏ nhiễu bằng thủ công sau đó cho chạy trên 3 mô hình: Linear Regression, Ridge, Random Forest thì cho kết quả ở mức R2score là khoảng 0.5. Kết hợp với những đánh giá cụ thể từ từng mô hình đã đi đến quyết định chọn mô hình Linear Regression cho việc dự đoán giá nhà.
"""